{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "### Kernel Density Estimation (KDE) Plots for Model Evaluation\n",
        "\n",
        "**Introduction**\n",
        "Kernel Density Estimation (KDE) plots are a valuable tool for visualizing data distributions by estimating their probability density function (PDF). These plots are particularly useful in regression analysis for comparing actual and predicted values. With the deprecation of Seaborn `distplot`, KDE plots serve as a modern and effective method for assessing model performance.\n",
        "\n",
        "---\n",
        "### Why Use KDE Plots?\n",
        "\n",
        "KDE plots are beneficial in model evaluation for the following reasons:\n",
        "* They provide a smooth approximation of the data distribution.\n",
        "* They help compare the true vs. predicted distributions effectively.\n",
        "* Unlike histograms, KDE plots are not sensitive to bin sizes.\n",
        "* They can highlight deviations between observed and predicted values.\n",
        "\n",
        "---\n",
        "### Implementing KDE Plots in Python\n",
        "\n",
        "We will use Seaborn `kdeplot()` function to implement a KDE plot, allowing us to compare the actual and predicted distributions effectively. It provides a smooth estimate of the data distribution, making it easier to visualize differences between observed and predicted values.\n",
        "\n",
        "---\n",
        "### Example: Evaluating a Regression Model\n",
        "The following code demonstrates how to train a simple linear regression model, generate predictions, and visualize the actual vs. predicted distributions using KDE plots. We will use synthetic data to simulate a linear relationship with added noise, then split the data into testing and training sets, and then we will evaluate the model predictions.\n",
        "\n",
        "---\n",
        "**Python Code Implementation (in separate Colab cells)**\n",
        "\n",
        "**Cell 1: Import Libraries**"
      ],
      "metadata": {
        "id": "AnklvOk4ZSNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as npy\n",
        "import pandas as pds\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error # Not used in plot, but relevant for model evaluation"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xUabythcZSNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Cell 2: Generating Sample Data**"
      ],
      "metadata": {
        "id": "tGmtSydIZSNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Sample Data\n",
        "npy.random.seed(42) # for reproducibility\n",
        "x_feature = npy.random.rand(100) * 10 # Feature: 100 random values between 0 and 10\n",
        "y_target = 3 * x_feature + npy.random.normal(0, 3, 100)  # Target: Linear relation with x_feature + Gaussian noise (mean=0, std_dev=3)\n",
        "data = pds.DataFrame({'X': x_feature, 'Y': y_target})\n",
        "\n",
        "print(\"First 5 rows of the generated data:\")\n",
        "print(data.head())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "43bR9LAgZSNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Cell 3: Splitting Data**"
      ],
      "metadata": {
        "id": "1Yg81aAVZSNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data[['X']],  # Feature(s) - note the double brackets to keep it as a DataFrame\n",
        "    data['Y'],    # Target variable\n",
        "    test_size=0.2, # 20% of data will be used for testing\n",
        "    random_state=42 # Ensures the split is the same every time, for reproducibility\n",
        ")\n",
        "\n",
        "print(f\"\\nShape of training features (X_train): {X_train.shape}\")\n",
        "print(f\"Shape of testing features (X_test): {X_test.shape}\")\n",
        "print(f\"Shape of training target (y_train): {y_train.shape}\")\n",
        "print(f\"Shape of testing target (y_test): {y_test.shape}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "UacPq2EwZSNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Cell 4: Training a Model and Making Predictions**"
      ],
      "metadata": {
        "id": "TX_IW4hUZSNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train) # Train the model using the training data\n",
        "\n",
        "# Generating predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nFirst 5 actual test values (y_test):\")\n",
        "print(y_test.head().values)\n",
        "print(\"First 5 predicted values (y_pred):\")\n",
        "print(y_pred[:5])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "NGO2LQErZSNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Cell 5: Plotting KDE for Observed vs. Predicted Values**"
      ],
      "metadata": {
        "id": "eIfM5JAYZSNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting KDE for Observed (Actual) vs. Predicted Values\n",
        "plt.figure(figsize=(10, 6)) # Set the figure size for better readability\n",
        "\n",
        "# KDE plot for actual values\n",
        "sns.kdeplot(y_test, label='Actual Values', fill=True, alpha=0.5, color='blue', linewidth=2)\n",
        "\n",
        "# KDE plot for predicted values\n",
        "sns.kdeplot(y_pred, label='Predicted Values', fill=True, alpha=0.5, color='red', linewidth=2)\n",
        "\n",
        "plt.xlabel('Target Variable Value') # Label for the x-axis\n",
        "plt.ylabel('Density') # Label for the y-axis\n",
        "plt.title('KDE Plot: Actual vs. Predicted Values Distribution') # Title of the plot\n",
        "plt.legend() # Show the legend to identify the curves\n",
        "plt.grid(True, linestyle='--', alpha=0.7) # Add a grid for easier reading\n",
        "plt.show() # Display the plot"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "kZaDjH-VZSNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Output**\n",
        "The resulted Kernel Density Estimation (KDE) plot compares the distribution of `actual values (blue)` and `predicted values (red)` from the linear regression model.\n",
        "\n",
        "---\n",
        "### Interpretation of the KDE Plot\n",
        "**Overlap Between Distributions:** The two curves have a significant overlap, indicating that the model has captured the general distribution of the actual target values reasonably well. However, the predicted values slightly deviate from the actual values in some regions.\n",
        "\n",
        "**Peak Differences (Mode Shifts):** The `blue (actual)` curve peaks slightly higher than the red curve, meaning that the actual values are more concentrated around certain values. The `red (predicted)` curve has a second peak, suggesting that the model may be slightly misestimating certain ranges of the target variable.\n",
        "\n",
        "**Spread of the Distributions:** The `actual values (blue)` seem to have a wider spread, indicating more variation in real-world values. The `predicted values (red)` appear to be narrower, which suggests the model might be slightly underestimating variance (a sign of over-smoothing or bias).\n",
        "\n",
        "**Tails of the Distributions:** The tails of the predicted values closely follow the actual values, meaning the model does not generate extreme outliers beyond what was observed in the data. If there was a significant mismatch in the tails, it could indicate that the model struggles with extreme cases.\n",
        "\n",
        "---\n",
        "### Conclusion\n",
        "KDE plots are a powerful visualization tool for assessing the distribution of predicted values compared to actual values in regression analysis. Replacing deprecated `distplot` with `kdeplot()` ensures modern and effective visualization in model evaluation workflows.\n",
        "\n",
        "---\n",
        "### Practice Questions (50)\n",
        "\n",
        "**Conceptual Understanding of KDE**\n",
        "\n",
        "1.  What does KDE stand for?\n",
        "2.  What is the primary purpose of a Kernel Density Estimation plot?\n",
        "3.  What does a KDE plot visually represent (e.g., PMF, PDF, CDF)?\n",
        "4.  How does a KDE plot differ visually from a histogram?\n",
        "5.  What is a \"kernel\" in the context of KDE? (General understanding)\n",
        "6.  What parameter in KDE can affect the \"smoothness\" of the resulting curve? (Hint: bandwidth)\n",
        "7.  Why is KDE considered a non-parametric method for density estimation?\n",
        "8.  Can KDE plots be used for both univariate and bivariate data?\n",
        "9.  What does the area under a KDE curve represent?\n",
        "10. If a KDE curve has a high peak at a certain value, what does it signify?\n",
        "\n",
        "**KDE Plots in Model Evaluation**\n",
        "\n",
        "11. Why are KDE plots useful for evaluating regression models?\n",
        "12. When comparing actual vs. predicted values using KDE, what would an ideal plot look like?\n",
        "13. What does it mean if the KDE plot of predicted values is much narrower than that of actual values?\n",
        "14. What might it indicate if the KDE plot of predicted values has its peak shifted to the right of the actual values' peak?\n",
        "15. If the tails of the predicted values' KDE plot are much \"fatter\" than the actual values' KDE, what could this imply about the model?\n",
        "16. Can KDE plots help identify if a model is systematically biased in its predictions? How?\n",
        "17. Why are KDE plots generally preferred over histograms for comparing distributions in model evaluation?\n",
        "18. What was the Seaborn function often used for plotting distributions (including KDE) before `kdeplot` became the primary recommendation?\n",
        "19. If two KDE curves (actual vs. predicted) have very little overlap, what does this suggest about the model's performance?\n",
        "20. How can KDE plots complement other numerical evaluation metrics like Mean Absolute Error (MAE) or R-squared?\n",
        "\n",
        "**Python Implementation (Seaborn `kdeplot`)**\n",
        "\n",
        "21. Which Python library is commonly used for creating KDE plots?\n",
        "22. What is the primary Seaborn function used to generate a KDE plot?\n",
        "23. What does the `data` parameter in `sns.kdeplot(data=...)` typically expect?\n",
        "24. How can you plot two KDEs (e.g., for `y_actual` and `y_predicted`) on the same axes using Seaborn?\n",
        "25. What does the `fill=True` argument do in `sns.kdeplot()`?\n",
        "26. How do you add a legend to a Seaborn plot that has multiple KDEs?\n",
        "27. What `matplotlib.pyplot` function is used to display the plot after defining it?\n",
        "28. How can you change the color of a KDE plot in Seaborn?\n",
        "29. What parameter in `sns.kdeplot()` might you adjust to change the smoothness of the density estimate?\n",
        "30. If you have a Pandas DataFrame `df` with a column 'values', how would you create a KDE plot for this column?\n",
        "\n",
        "**Interpretation of KDE Plots (Scenarios)**\n",
        "\n",
        "*Imagine you are looking at a KDE plot comparing 'Actual Values' (blue) and 'Predicted Values' (red) from a regression model.*\n",
        "\n",
        "31. If the red curve is almost identical to the blue curve, what does this imply?\n",
        "32. If the blue curve shows two distinct peaks (bimodal) but the red curve shows only one peak, what does this suggest?\n",
        "33. If the red curve's peak is significantly lower and wider than the blue curve's peak, but they are centered at the same value, what could this mean?\n",
        "34. If the red curve is consistently to the left of the blue curve, what type of error might the model be making?\n",
        "35. If both curves have similar shapes and peaks, but the red curve's tails are much shorter (cut off) compared to the blue curve, what is a potential issue?\n",
        "36. You observe that the predicted values' KDE (red) has a small, unexpected bump in an area where the actual values' KDE (blue) is near zero. What might this indicate?\n",
        "37. If the KDE for predicted values is perfectly symmetrical around zero, while the actual values are skewed, what does it say about the model?\n",
        "38. How would you interpret a situation where the actual values show a wide spread, but the predicted values are tightly clustered, resulting in a very narrow KDE?\n",
        "39. If a model is improved, how would you expect the KDE plot of its predictions (compared to actuals) to change?\n",
        "40. Can a KDE plot tell you if your model is overfitting? How might it give clues? (Hint: Compare training set predictions vs. test set predictions if possible, or consider the narrowness of test predictions).\n",
        "\n",
        "**General & Comparative Questions**\n",
        "\n",
        "41. Besides regression, what other types of model evaluation or data analysis might benefit from KDE plots?\n",
        "42. What is one advantage of KDE plots over a simple scatter plot of actual vs. predicted values?\n",
        "43. What is one disadvantage or limitation of using KDE plots for model evaluation?\n",
        "44. How does sample size affect the reliability or appearance of a KDE plot?\n",
        "45. True or False: KDE plots can directly provide a numerical score of model accuracy.\n",
        "46. In the provided example code, what is the purpose of `npy.random.seed(42)`?\n",
        "47. What does `test_size=0.2` in `train_test_split` signify?\n",
        "48. If `fill=True` is used for two overlapping KDEs, what argument can help distinguish them better? (Hint: `alpha`)\n",
        "49. Why is it important to evaluate a model on a separate *test set* rather than the *training set* when plotting these KDEs for performance assessment?\n",
        "50. If the KDE plots for actual and predicted values are very different, what might be your next steps in the model improvement process?"
      ],
      "metadata": {
        "id": "HjzRTfpEZSNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://github.com/vaish-o5/CODSOFT\">https://github.com/vaish-o5/CODSOFT</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "7CPUcQ0RZSNu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}